{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chatgpt.com/c/674a7838-11bc-800b-abf7-38663d8d5598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model building and evaluation\n",
    "# from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "# from sklearn.metrics import (\n",
    "#     r2_score,\n",
    "#     mean_squared_error,\n",
    "#     mean_absolute_error,\n",
    "#     mean_absolute_percentage_error,\n",
    "# )\n",
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, TimeSeriesSplit\n",
    "\n",
    "\n",
    "\n",
    "# class LinearRegressionModel:\n",
    "#     def __init__(self, X_train, y_train, model, param_gird_or_dist, search_type):\n",
    "#         \"\"\"\n",
    "#         Constructor for Linear Regression Model Class.\n",
    "\n",
    "#         :param X_train: (pandas DataFrame) feature training set\n",
    "#         :param y_train: (numpy array) target training set\n",
    "#         :param model: (sklearn regression model type) type of regression model to use\n",
    "#         :param param_distributions: (dictionary) dictionary containing hyperparameters for the model\n",
    "#         :param search_type: (string) type of randomized search ('grid_search' or 'random_search')\n",
    "#         \"\"\"\n",
    "#         self.X_train = X_train\n",
    "#         self.y_train = y_train\n",
    "\n",
    "#         # Initialize regression model to search for best hyperparameters\n",
    "#         self.model = model()\n",
    "#         self.param_gird_or_dist = param_gird_or_dist\n",
    "#         self.tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "#         # self.best_search_model\n",
    "#         if search_type == 'grid_search':\n",
    "#             self.gird_or_dist_search_model = GridSearchCV(estimator=self.model, param_grid=self.param_gird_or_dist, cv=self.tscv)\n",
    "#         elif search_type == 'random_search':\n",
    "#             self.gird_or_dist_search_model = RandomizedSearchCV(estimator=self.model, param_distributions=self.param_gird_or_dist, cv=self.tscv)\n",
    "#         else:\n",
    "#             raise ValueError('search_type should be either \"grid_search\" or \"random_search\"')\n",
    "\n",
    "#     def print_best_param(self):\n",
    "#         \"\"\"\n",
    "#         Find the best hyperparameters for the linear regression model using RandomizedSearchCV.\n",
    "#         \"\"\"\n",
    "#         self.gird_or_dist_search_model.fit(self.X_train, self.y_train)\n",
    "#         print(\"Best parameters found: \", self.gird_or_dist_search_model.best_params_)\n",
    "\n",
    "#         # best_linear_reg_model with best_estimator c·ªßa gird_or_dist_search_model\n",
    "#         self.best_linear_reg_model = self.gird_or_dist_search_model.best_estimator_\n",
    "\n",
    "#     def get_coef_pdSeries(self):\n",
    "#         # Tr·∫£ v·ªÅ pandas Series ch·ª©a h·ªá s·ªë c·ªßa c√°c features\n",
    "#         coef_np = self.best_linear_reg_model.coef_      # <class 'numpy.ndarray'>\n",
    "#         coef_pdSeries = pd.Series(coef_np, index=X_train.columns) # t·∫°o pandas Series obj ch·ª©a coef_ v√† index/g√°n nh√£n n√≥ = t√™n c·ªôt c·ªßa X\n",
    "#         return coef_pdSeries # <class 'pandas.core.series.Series'>, t∆∞∆°ng t·ª± df, but have only 1 col, tuple (index)\n",
    "\n",
    "#     def print_important_features(self):\n",
    "#         # Tr·∫£ v·ªÅ danh s√°ch c√°c feature quan tr·ªçng (c√≥ h·ªá s·ªë kh√°c 0)\n",
    "#         coef_np = self.best_linear_reg_model.coef_\n",
    "#         important_features = self.X_train.columns[coef_np != 0]\n",
    "#         print('Important features:', important_features)\n",
    "\n",
    "#     def plot_coef_bar(self):\n",
    "#         \"\"\"\n",
    "#         Plot bar graph showing the coefficients for each feature in the trained linear regression model.\n",
    "#         \"\"\"\n",
    "#         coef_pdSeries = pd.Series(self.best_linear_reg_model.coef_, index=self.X_train.columns)\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         coef_pdSeries.plot(kind='bar')\n",
    "\n",
    "#         plt.title('Linear Regression Coefficients')\n",
    "#         plt.xlabel('Features')\n",
    "#         plt.ylabel('Coefficient Values')\n",
    "#         plt.show()\n",
    "\n",
    "#     def evaluate_model(self, y_train, y_pred_train, y_test, y_pred_test): #\n",
    "#         \"\"\"\n",
    "#         parameters: `y_train`, `y_pred_train`, `y_test`, `y_pred_test`\n",
    "#         calculates evaluation metrics,\n",
    "#            including R-squared, MSE, RMSE, MAE, MAPE,\n",
    "#         \"\"\"\n",
    "#         y_pred_train = self.best_linear_reg_model.predict(X_train)\n",
    "#         y_pred_test = self.best_linear_reg_model.predict(X_test)\n",
    "\n",
    "#         print('EVALUATE METRICS ON THE TRAIN SET')\n",
    "#         print('Coefficient of determination R2:', r2_score(y_train, y_pred_train)) # print(model.score(X_test, y_train))\n",
    "#         print('Mean Squared Error MSE:', mean_squared_error(y_train, y_pred_train))\n",
    "#         print('Root Mean Squared Error RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "#         print('Mean Absolute Error MAE:', mean_absolute_error(y_train, y_pred_train))\n",
    "#         MAPE = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "#         # MAPE = np.mean(np.abs((np.array(y_train) - np.array(y_pred_train)) / y_train))\n",
    "#         print('Mean Absolute Percentage Error MAPE%', f\"{round(MAPE*100, 2)}%\", '\\n')\n",
    "\n",
    "#         print('EVALUATE METRICS ON THE TEST SET')\n",
    "#         print('Coefficient of determination R2:', r2_score(y_test, y_pred_test)) # print(model.score(X_test, y_test))\n",
    "#         print('Mean Squared Error MSE:', mean_squared_error(y_test, y_pred_test))\n",
    "#         print('Root Mean Squared Error RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "#         print('Mean Absolute Error MAE:', mean_absolute_error(y_test, y_pred_test))\n",
    "#         MAPE = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "#         # MAPE = np.mean(np.abs((np.array(y_test) - np.array(y_pred_test)) / y_test))\n",
    "#         print('Mean Absolute Percentage Error MAPE%', f\"{round(MAPE*100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ƒê·ªÉ gi·∫£i th√≠ch chi ti·∫øt v√† d·ªÖ hi·ªÉu h∆°n, m√¨nh s·∫Ω chia nh·ªè v·∫•n ƒë·ªÅ ra:\n",
    "\n",
    "---\n",
    "\n",
    "### **V·∫•n ƒê·ªÅ Ch√≠nh**\n",
    "1. **`y_pred_train` v√† `y_pred_test` kh√¥ng c·∫ßn truy·ªÅn v√†o `evaluate_model`:**\n",
    "   - Tr∆∞·ªõc ƒë√≥, b·∫°n y√™u c·∫ßu c√°c gi√° tr·ªã d·ª± ƒëo√°n (`y_pred_train`, `y_pred_test`) ph·∫£i ƒë∆∞·ª£c t√≠nh s·∫µn v√† truy·ªÅn v√†o h√†m `evaluate_model`.\n",
    "   - Nh∆∞ng th·ª±c t·∫ø, b·∫°n ƒë√£ c√≥ m√¥ h√¨nh t·ªët nh·∫•t (`self.best_linear_reg_model`) trong class. D√πng m√¥ h√¨nh n√†y ƒë·ªÉ t·ª± ƒë·ªông t√≠nh d·ª± ƒëo√°n trong h√†m `evaluate_model` m√† kh√¥ng c·∫ßn truy·ªÅn th√™m gi√° tr·ªã.\n",
    "\n",
    "2. **`X_train`, `X_test` ch∆∞a ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong class:**\n",
    "   - Trong m·ªôt s·ªë h√†m (nh∆∞ `get_coef_pdSeries` ho·∫∑c `evaluate_model`), b·∫°n d√πng `X_train`, `X_test` nh∆∞ng l·∫°i kh√¥ng truy·ªÅn `X_test` v√†o constructor c·ªßa class.\n",
    "\n",
    "3. **L·ªói ti·ªÅm ·∫©n: G·ªçi m√¥ h√¨nh khi ch∆∞a hu·∫•n luy·ªán**\n",
    "   - N·∫øu b·∫°n qu√™n g·ªçi `print_best_param` tr∆∞·ªõc, th√¨ `self.best_linear_reg_model` s·∫Ω kh√¥ng t·ªìn t·∫°i, g√¢y l·ªói khi truy c·∫≠p.\n",
    "\n",
    "---\n",
    "\n",
    "### **C√°ch Gi·∫£i Quy·∫øt**\n",
    "\n",
    "#### 1. **X·ª≠ l√Ω `evaluate_model`**\n",
    "- ƒê·ªÉ t·ª± ƒë·ªông t√≠nh `y_pred_train` v√† `y_pred_test`, ch√∫ng ta s·∫Ω d√πng `self.best_linear_reg_model` tr·ª±c ti·∫øp.\n",
    "- Kh√¥ng c·∫ßn y√™u c·∫ßu ng∆∞·ªùi d√πng truy·ªÅn `y_pred_train`, `y_pred_test`.\n",
    "\n",
    "C·∫≠p nh·∫≠t h√†m:\n",
    "```python\n",
    "def evaluate_model(self, y_train, y_test, X_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance using various metrics.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_train : array-like\n",
    "        True values for training data.\n",
    "    y_test : array-like\n",
    "        True values for test data.\n",
    "    X_test : array-like\n",
    "        Feature data for test set.\n",
    "    \"\"\"\n",
    "    if self.best_linear_reg_model is None:\n",
    "        raise ValueError(\"The model has not been fitted yet. Call `print_best_param()` first.\")\n",
    "    \n",
    "    # T·ª± ƒë·ªông t√≠nh to√°n d·ª± ƒëo√°n\n",
    "    y_pred_train = self.best_linear_reg_model.predict(self.X_train)\n",
    "    y_pred_test = self.best_linear_reg_model.predict(X_test)\n",
    "\n",
    "    # ƒê√°nh gi√° tr√™n t·∫≠p train\n",
    "    print(\"EVALUATE METRICS ON THE TRAIN SET\")\n",
    "    print(f\"R2 Score: {r2_score(y_train, y_pred_train):.4f}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_train, y_pred_train):.4f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train)):.4f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_train, y_pred_train):.4f}\")\n",
    "    print(f\"MAPE: {mean_absolute_percentage_error(y_train, y_pred_train) * 100:.2f}%\\n\")\n",
    "\n",
    "    # ƒê√°nh gi√° tr√™n t·∫≠p test\n",
    "    print(\"EVALUATE METRICS ON THE TEST SET\")\n",
    "    print(f\"R2 Score: {r2_score(y_test, y_pred_test):.4f}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_test, y_pred_test):.4f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.4f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred_test):.4f}\")\n",
    "    print(f\"MAPE: {mean_absolute_percentage_error(y_test, y_pred_test) * 100:.2f}%\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Truy·ªÅn `X_test` khi s·ª≠ d·ª•ng**\n",
    "- Khi b·∫°n g·ªçi h√†m `evaluate_model`, b·∫°n c·∫ßn truy·ªÅn th√™m `X_test` v√¨ `X_test` kh√¥ng ph·∫£i l√† thu·ªôc t√≠nh c·ªßa class.\n",
    "\n",
    "V√≠ d·ª•:\n",
    "```python\n",
    "ridge_model.evaluate_model(y_train, y_test, X_test)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **ƒê·∫£m b·∫£o m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán**\n",
    "- Tr∆∞·ªõc khi s·ª≠ d·ª•ng c√°c h√†m nh∆∞ `evaluate_model`, `get_coef_pdSeries`, b·∫°n **ph·∫£i g·ªçi `print_best_param()` tr∆∞·ªõc** ƒë·ªÉ ch·ªçn ƒë∆∞·ª£c m√¥ h√¨nh t·ªët nh·∫•t (`self.best_linear_reg_model`).\n",
    "- N·∫øu ch∆∞a g·ªçi, `self.best_linear_reg_model` s·∫Ω kh√¥ng t·ªìn t·∫°i v√† g√¢y l·ªói.\n",
    "\n",
    "---\n",
    "\n",
    "### **V√≠ D·ª• Ho√†n Ch·ªânh**\n",
    "\n",
    "```python\n",
    "# ƒê·ªãnh nghƒ©a tham s·ªë\n",
    "param_Ridge = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['auto', 'svd', 'lsqr', 'sag'],\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter': [1000, 5000],\n",
    "    'tol': [0.001, 0.0001],\n",
    "    'positive': [True, False],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# T·∫°o class LinearRegressionModel cho Ridge Regression\n",
    "ridge_model = LinearRegressionModel(X_train, y_train, Ridge, param_Ridge, 'random_search')\n",
    "\n",
    "# T√¨m tham s·ªë t·ªët nh·∫•t\n",
    "ridge_model.print_best_param()\n",
    "\n",
    "# Hi·ªÉn th·ªã h·ªá s·ªë\n",
    "print(\"Coefficients:\")\n",
    "print(ridge_model.get_coef_pdSeries())\n",
    "\n",
    "# Tr·ª±c quan h√≥a h·ªá s·ªë\n",
    "ridge_model.plot_coef_bar()\n",
    "\n",
    "# ƒê√°nh gi√° m√¥ h√¨nh\n",
    "ridge_model.evaluate_model(y_train, y_test, X_test)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **T√≥m T·∫Øt**\n",
    "1. **S·ª≠a `evaluate_model`**:\n",
    "   - T·ª± ƒë·ªông t√≠nh to√°n `y_pred_train` v√† `y_pred_test` t·ª´ m√¥ h√¨nh t·ªët nh·∫•t.\n",
    "   - Y√™u c·∫ßu ng∆∞·ªùi d√πng truy·ªÅn `X_test`, kh√¥ng c·∫ßn truy·ªÅn `y_pred_train` v√† `y_pred_test`.\n",
    "\n",
    "2. **ƒê·∫£m b·∫£o s·ª≠ d·ª•ng ƒë√∫ng th·ª© t·ª±**:\n",
    "   - G·ªçi `print_best_param()` tr∆∞·ªõc khi g·ªçi c√°c h√†m kh√°c ƒë·ªÉ m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán.\n",
    "\n",
    "3. **H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng**:\n",
    "   - Truy·ªÅn th√™m `X_test` khi g·ªçi `evaluate_model`.\n",
    "\n",
    "N·∫øu b·∫°n v·∫´n g·∫∑p v·∫•n ƒë·ªÅ, h√£y cho m√¨nh bi·∫øt ƒë·ªÉ h·ªó tr·ª£ th√™m! üòä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **·ª®ng D·ª•ng Trong B√†i To√°n Hi·ªán T·∫°i**\n",
    "\n",
    "Trong b√†i to√°n d·ª± ƒëo√°n **x√°c su·∫•t l≈© l·ª•t (FloodProbability)**, ch√∫ng ta c·∫ßn t·ªëi ∆∞u h√≥a c√°c tham s·ªë c·ªßa m√¥ h√¨nh Ridge Regression ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c d·ª± ƒëo√°n ch√≠nh x√°c nh·∫•t. C√°c b∆∞·ªõc ·ª©ng d·ª•ng Grid Search v√† Randomized Search trong b√†i to√°n n√†y bao g·ªìm:\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. X√°c ƒë·ªãnh c√°c tham s·ªë c·∫ßn t·ªëi ∆∞u**\n",
    "- Trong Ridge Regression, ch√∫ng ta c√≥ c√°c tham s·ªë c·∫ßn t·ªëi ∆∞u h√≥a:\n",
    "  - **`alpha`**: ƒêi·ªÅu ch·ªânh ƒë·ªô m·∫°nh c·ªßa regularization (gi·∫£m overfitting).\n",
    "  - **`solver`**: Ch·ªçn ph∆∞∆°ng ph√°p to√°n h·ªçc ƒë·ªÉ t√¨m h·ªá s·ªë (vd: `auto`, `svd`, `lsqr`).\n",
    "  - **`fit_intercept`**: Quy·∫øt ƒë·ªãnh c√≥ th√™m h·ªá s·ªë ch·∫∑n (intercept) v√†o c√¥ng th·ª©c hay kh√¥ng.\n",
    "  - **`max_iter`**: S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa c·ªßa thu·∫≠t to√°n.\n",
    "  - **`tol`**: Ng∆∞·ª°ng sai s·ªë nh·ªè nh·∫•t ƒë·ªÉ thu·∫≠t to√°n d·ª´ng.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. S·ª≠ d·ª•ng Randomized Search ƒë·ªÉ t·ªëi ∆∞u tham s·ªë**\n",
    "- Randomized Search ph√π h·ª£p v·ªõi b√†i to√°n hi·ªán t·∫°i v√¨ s·ªë l∆∞·ª£ng tham s·ªë l·ªõn v√† c·∫ßn ti·∫øt ki·ªám th·ªùi gian t√≠nh to√°n.\n",
    "- Ch√∫ng ta th·ª≠ ng·∫´u nhi√™n m·ªôt s·ªë k·∫øt h·ª£p c·ªßa c√°c gi√° tr·ªã `alpha`, `solver`, `fit_intercept`, v.v., ƒë·ªÉ t√¨m ra tham s·ªë t·ªët nh·∫•t.\n",
    "\n",
    "**V√≠ d·ª• ƒëo·∫°n code:**\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a c√°c tham s·ªë\n",
    "param_Ridge = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['auto', 'svd', 'lsqr', 'sag'],\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter': [None, 1000, 5000],\n",
    "    'tol': [0.001, 0.0001, 0.00001],\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "# S·ª≠ d·ª•ng RandomizedSearchCV ƒë·ªÉ t·ªëi ∆∞u\n",
    "ridge_model = Ridge()\n",
    "random_search = RandomizedSearchCV(estimator=ridge_model, param_distributions=param_Ridge, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# In ra tham s·ªë t·ªët nh·∫•t\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. ƒê√°nh gi√° k·∫øt qu·∫£ v·ªõi tham s·ªë t·ªëi ∆∞u**\n",
    "- Sau khi t√¨m ƒë∆∞·ª£c tham s·ªë t·ªët nh·∫•t, ch√∫ng ta s·ª≠ d·ª•ng m√¥ h√¨nh v·ªõi c√°c tham s·ªë n√†y ƒë·ªÉ d·ª± ƒëo√°n v√† ƒë√°nh gi√°.\n",
    "- ƒê√°nh gi√° hi·ªáu qu·∫£ c·ªßa m√¥ h√¨nh qua c√°c ch·ªâ s·ªë:\n",
    "  - **R¬≤ Score**: ƒê·ªô gi·∫£i th√≠ch c·ªßa m√¥ h√¨nh.\n",
    "  - **Mean Squared Error (MSE)**: Sai s·ªë trung b√¨nh b√¨nh ph∆∞∆°ng.\n",
    "  - **Mean Absolute Error (MAE)**: Sai s·ªë trung b√¨nh tuy·ªát ƒë·ªëi.\n",
    "\n",
    "**V√≠ d·ª• ƒëo·∫°n code:**\n",
    "```python\n",
    "# L·∫•y m√¥ h√¨nh t·ªët nh·∫•t t·ª´ RandomizedSearchCV\n",
    "best_ridge_model = random_search.best_estimator_\n",
    "\n",
    "# D·ª± ƒëo√°n tr√™n t·∫≠p train v√† test\n",
    "y_pred_train = best_ridge_model.predict(X_train)\n",
    "y_pred_test = best_ridge_model.predict(X_test)\n",
    "\n",
    "# ƒê√°nh gi√° m√¥ h√¨nh\n",
    "print(\"Train R2 Score:\", r2_score(y_train, y_pred_train))\n",
    "print(\"Test R2 Score:\", r2_score(y_test, y_pred_test))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, y_pred_test))\n",
    "print(\"Test MAE:\", mean_absolute_error(y_test, y_pred_test))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. √ù nghƒ©a c·ªßa ·ª©ng d·ª•ng**\n",
    "- Vi·ªác t·ªëi ∆∞u tham s·ªë gi√∫p m√¥ h√¨nh Ridge Regression ƒë·∫°t hi·ªáu qu·∫£ cao nh·∫•t.\n",
    "- Gi·∫£m hi·ªán t∆∞·ª£ng **overfitting** (m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët tr√™n t·∫≠p train nh∆∞ng k√©m tr√™n t·∫≠p test).\n",
    "- C·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c khi d·ª± ƒëo√°n **x√°c su·∫•t l≈© l·ª•t**, gi√∫p ch√∫ng ta hi·ªÉu ƒë∆∞·ª£c c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng m·∫°nh nh·∫•t ƒë·∫øn l≈© l·ª•t.\n",
    "\n",
    "---\n",
    "\n",
    "### **T√≥m l·∫°i**\n",
    "- Trong b√†i to√°n d·ª± ƒëo√°n **FloodProbability**, vi·ªác s·ª≠ d·ª•ng Randomized Search gi√∫p ti·∫øt ki·ªám th·ªùi gian t√¨m ki·∫øm tham s·ªë t·ªëi ∆∞u so v·ªõi Grid Search.\n",
    "- T·ªëi ∆∞u tham s·ªë c·∫£i thi·ªán hi·ªáu su·∫•t d·ª± ƒëo√°n, t·ª´ ƒë√≥ h·ªó tr·ª£ ra quy·∫øt ƒë·ªãnh li√™n quan ƒë·∫øn ph√≤ng ch·ªëng l≈© l·ª•t."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
